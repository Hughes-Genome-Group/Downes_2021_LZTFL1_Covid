
configfile: "snake_conf.yaml"

import glob


def read_samples():
    """Function to get names and fastq paths from a sample file specified
    in the configuration. Input file is expected to have 4 columns:
    <1000genomes_id> <unique_sample_id> <fastq1_path> <fastq2_path>. Modify this function
    as needed to provide a dictionary of sample_id keys and (fastq1, fastq1) 
    values"""
    f = open(config['sample_file'], "r")
    samp_dict = {}
    for line in f:
        words = line.strip().split()
        samp_dict[words[1]] = (words[2], words[3])

    return samp_dict

def get_chromosomes():
    """Gets list of chromosomes with from VCF files"""
    filenames = os.listdir(config['vcf_dir'])

    chr_names = set([])
    for filename in filenames:
        if filename.endswith(".vcf.gz"):
            m = re.match(".*(chr[0-9A-Z]+).*", filename)
            if m:
                chr_names.add(m.groups()[0])

    return chr_names
    

rule all:
    input:
        expand(config['output_dir'] + "/read_count/{sample}.wasp_gwas.count.txt",
               sample=read_samples().keys()),
        expand(config['output_dir'] + "/bias_test/{sample}.wasp_gwas.bias.txt",
               sample=read_samples().keys())

rule find_intersecting_snps_single_end:
    """find intersecting SNPs using WASP script"""
    input:
        bam=config["output_dir"] + "/map1_sort/{sample}.bam",
        snps=[config["snp_dir"] + "/%s.snps.txt.gz" % s for s in get_chromosomes()]
    output:
        fastq1=config["output_dir"] + "/find_intersecting_snps/{sample}.remap.fq.gz",
        keep_bam=config["output_dir"] + "/find_intersecting_snps/{sample}.keep.bam",
        remap_bam=config["output_dir"] + "/find_intersecting_snps/{sample}.to.remap.bam"
    shell:
        "python {config[wasp_dir]}/mapping/find_intersecting_snps.py "
        "    --is_sorted --output_dir {config[output_dir]}/find_intersecting_snps --snp_dir {config[snp_dir]} {input.bam}"

         
rule map_bowtie2_single_end1:
    """map reads using bowtie2"""
    input:
        fastq1=lambda wildcards: read_samples()[wildcards.sample][0]
    output:
        config["output_dir"] + "/map1/{sample}.bam" 
    threads: 4
    shell:
        "{config[bowtie2]} -p {threads} -x {config[bowtie2_index]} -U {input.fastq1} "
        "| {config[samtools]} view -b -q 10 - > {output} "


rule sort_and_index_bam1:
    """sort and index bam generated by first mapping step"""
    input:
        config["output_dir"] + "/map1/{sample}.bam"
    output:
        config["output_dir"] + "/map1_sort/{sample}.bam",
        config["output_dir"] + "/map1_sort/{sample}.bam.bai"
    shell:
        "{config[samtools]} sort -o {output[0]} {input}; "
        "{config[samtools]} index {output[0]}"



rule map_bowtie2_single_end2:
    """map reads a second time using bowtie2"""
    input:
        fastq1=config['output_dir'] + "/find_intersecting_snps/{sample}.remap.fq.gz",
    output:
        config["output_dir"] + "/map2/{sample}.bam"
    threads: 4
    shell:
        "{config[bowtie2]} -p {threads}  -x {config[bowtie2_index]} -U {input.fastq1} "
        "| {config[samtools]} view -b -q 10 - > {output}"
        

rule sort_and_index_bam2:
    """sort and index bam generated by second mapping step"""
    input:
        config["output_dir"] + "/map2/{sample}.bam"
    output:
        config["output_dir"] + "/map2_sort/{sample}.bam",
        config["output_dir"] + "/map2_sort/{sample}.bam.bai"
    shell:
        "{config[samtools]} sort -o {output[0]} {input} ; "
        "{config[samtools]} index {output[0]}"


rule filter_remapped_reads:
    """filter reads from second mapping step"""
    input:
        to_remap_bam=config['output_dir'] + "/find_intersecting_snps/{sample}.to.remap.bam",
        remap_bam=config['output_dir'] + "/map2_sort/{sample}.bam",
    output:
        keep_bam=config['output_dir'] + "/filter_remapped_reads/{sample}.keep.bam"
    shell:
        "python {config[wasp_dir]}/mapping/filter_remapped_reads.py "
        "  {input.to_remap_bam} {input.remap_bam} {output.keep_bam}"

    
rule merge_bams:
    """merge 'keep' BAM files from mapping steps 1 and 2, then sort and index"""
    input:
        keep1=config['output_dir'] + "/find_intersecting_snps/{sample}.keep.bam",
        keep2=config['output_dir'] + "/filter_remapped_reads/{sample}.keep.bam"
    output:
        merge=config['output_dir'] + "/merge/{sample}.keep.merge.bam",
        sort=config['output_dir'] + "/merge/{sample}.keep.merge.sort.bam"
    shell:
        "{config[samtools]} merge {output.merge} {input.keep1} {input.keep2}; "
        "{config[samtools]} sort -o {output.sort} {output.merge}; "
        "{config[samtools]} index {output.sort}"

    
rule rmdup_pe:
    """remove duplicate reads"""
    input:
        mergein=config['output_dir'] + "/merge/{sample}.keep.merge.sort.bam"
    output:
        rmdup=config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.bam",
        sort=config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.sort.bam"
    shell:
        "python {config[wasp_dir]}/mapping/rmdup.py {input.mergein} {output.rmdup} ;"
        "{config[samtools]} sort -o {output.sort} {output.rmdup}; "
        "{config[samtools]} index {output.sort};"

rule bias_test:
    """test for allelic bias"""
    input:
        mergein=config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.sort.bam"
    output:
        mergetest=config['output_dir'] + "/bias_test/{sample}.wasp_gwas.bias.txt"
    shell:
        """
        python {config[utility_dir]}/dnase_atac_related/allele_specific_dnase.py \
        -s {config[test_snps]} \
        -b {input.mergein} \
        --min_baseq 10 --min_reads 2 --sortby position --report all >{output.mergetest}
        """

rule read_count:
    """count mapped reads"""
    input:
        config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.sort.bam"
    output:
        config['output_dir'] + "/read_count/{sample}.wasp_gwas.count.txt"
    shell:
        """
        samtools view -c {input} >{output}
        """

        
#rule get_as_counts:
#    """get allele-specific read counts for SNPs"""
#    input:
#        bam=config['output_dir'] + "/rmdup/{sample}.keep.merge.rmdup.sort.bam",
#        snp_index=config["snp_h5_dir"] + "/snp_index.h5",
#        snp_tab=config["snp_h5_dir"] + "/snp_tab.h5",
#        haplotype=config['snp_h5_dir'] + "/haplotype.h5",
#        chrom=config['chrom_info']
#    params:
#        samp1kg=lambda wildcards: SAMP_TO_1KG[wildcards.sample]
#    output:
#        ref_as=config['output_dir'] + "/as_counts/{sample}.ref_as_counts.h5",
#        alt_as=config['output_dir'] + "/as_counts/{sample}.alt_as_counts.h5",
#        other_as=config['output_dir'] + "/as_counts/{sample}.other_as_counts.h5",
#        read_counts=config['output_dir'] + "/as_counts/{sample}.read_counts.h5",
#        txt_counts=config['output_dir'] + "/as_counts/{sample}.as_counts.txt.gz"
#    shell:
#        "python {config[wasp_dir]}/CHT/bam2h5.py "
#        "  --chrom {input.chrom} "
#        "  --snp_index {input.snp_index} "
#        "  --snp_tab {input.snp_tab} "
#        "  --haplotype {input.haplotype} "
#        "  --individual {params.samp1kg} "
#        "  --ref_as_counts {output.ref_as} "
#        "  --alt_as_counts {output.alt_as} "
#        "  --other_as_counts {output.other_as} "
#        "  --read_counts {output.read_counts} "
#        "  --txt_counts {output.txt_counts} "
#        "{input.bam}"
